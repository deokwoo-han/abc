{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.08 tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deokwoo-han/abc/blob/master/10_08_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvhYZrIZCEyo"
      },
      "source": [
        "<img src=\"https://user-images.githubusercontent.com/26833433/98702494-b71c4e80-237a-11eb-87ed-17fcd6b3f066.jpg\">\n",
        "\n",
        "This notebook was written by Ultralytics LLC, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
        "For more information please visit https://github.com/ultralytics/yolov5 and https://www.ultralytics.com."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba84460-3e40-463d-bf43-9d957c7bf229"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.9.0+cu111 _CudaDeviceProperties(name='Tesla K80', major=3, minor=7, total_memory=11441MB, multi_processor_count=13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Inference\n",
        "\n",
        "`detect.py` runs inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txvj1CECAf89",
        "outputId": "23c6b676-70f6-4d01-83bc-7042bb6156ca"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rpRui3E9aRs",
        "outputId": "7257b0f5-06f9-4519-8590-8bbaff765ba0"
      },
      "source": [
        "!python detect.py --img 640  --source ../elephant2.png \n",
        "#jpg 확률 86%"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=../elephant2.png, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 🚀 v5.0-499-g48b00db torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
            "image 1/1 /content/elephant2.png: 384x640 2 elephants, Done. (0.031s)\n",
            "Speed: 0.5ms pre-process, 31.0ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry6-05Fs_oii"
      },
      "source": [
        "!python detect.py --source ../elephant2.png \n",
        "#jpg 확률 86%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr-fb5si_dDj",
        "outputId": "7418ecb6-1f4c-4d22-e415-ffec4f1a93b9"
      },
      "source": [
        "!python detect.py --source ../20201009.mp4"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=../20201009.mp4, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 🚀 v5.0-499-g48b00db torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
            "video 1/1 (1/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.031s)\n",
            "video 1/1 (2/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (3/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (4/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (5/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (6/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (7/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (8/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (9/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (10/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (11/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (12/318) /content/20201009.mp4: 384x640 2 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (13/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (14/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (15/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (16/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (17/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (18/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (19/318) /content/20201009.mp4: 384x640 5 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (20/318) /content/20201009.mp4: 384x640 6 persons, 2 bicycles, 1 motorcycle, Done. (0.030s)\n",
            "video 1/1 (21/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (22/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (23/318) /content/20201009.mp4: 384x640 5 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (24/318) /content/20201009.mp4: 384x640 5 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (25/318) /content/20201009.mp4: 384x640 5 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (26/318) /content/20201009.mp4: 384x640 5 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (27/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (28/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (29/318) /content/20201009.mp4: 384x640 5 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (30/318) /content/20201009.mp4: 384x640 5 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (31/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (32/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (33/318) /content/20201009.mp4: 384x640 2 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (34/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (35/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (36/318) /content/20201009.mp4: 384x640 2 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (37/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (38/318) /content/20201009.mp4: 384x640 5 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (39/318) /content/20201009.mp4: 384x640 5 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (40/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (41/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (42/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (43/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (44/318) /content/20201009.mp4: 384x640 2 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (45/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (46/318) /content/20201009.mp4: 384x640 2 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (47/318) /content/20201009.mp4: 384x640 2 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (48/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (49/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (50/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (51/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (52/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (53/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (54/318) /content/20201009.mp4: 384x640 2 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (55/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (56/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (57/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (58/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (59/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (60/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (61/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (62/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (63/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (64/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (65/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (66/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (67/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (68/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (69/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (70/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (71/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (72/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (73/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (74/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (75/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (76/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (77/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (78/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (79/318) /content/20201009.mp4: 384x640 5 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (80/318) /content/20201009.mp4: 384x640 5 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (81/318) /content/20201009.mp4: 384x640 5 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (82/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.031s)\n",
            "video 1/1 (83/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (84/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (85/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (86/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (87/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (88/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (89/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (90/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (91/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (92/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (93/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (94/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (95/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (96/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (97/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (98/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (99/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (100/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (101/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (102/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (103/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (104/318) /content/20201009.mp4: 384x640 3 persons, 4 bicycles, Done. (0.030s)\n",
            "video 1/1 (105/318) /content/20201009.mp4: 384x640 3 persons, 4 bicycles, Done. (0.030s)\n",
            "video 1/1 (106/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (107/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (108/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (109/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (110/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (111/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (112/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (113/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (114/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (115/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (116/318) /content/20201009.mp4: 384x640 2 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (117/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (118/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (119/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (120/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (121/318) /content/20201009.mp4: 384x640 3 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (122/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (123/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (124/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (125/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (126/318) /content/20201009.mp4: 384x640 4 persons, 3 bicycles, Done. (0.030s)\n",
            "video 1/1 (127/318) /content/20201009.mp4: 384x640 4 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (128/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (129/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (130/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (131/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (132/318) /content/20201009.mp4: 384x640 4 persons, 1 skateboard, Done. (0.030s)\n",
            "video 1/1 (133/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (134/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (135/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, 1 motorcycle, Done. (0.030s)\n",
            "video 1/1 (136/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (137/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (138/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (139/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (140/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (141/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, 1 car, Done. (0.030s)\n",
            "video 1/1 (142/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (143/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, 1 car, Done. (0.030s)\n",
            "video 1/1 (144/318) /content/20201009.mp4: 384x640 4 persons, 1 car, Done. (0.030s)\n",
            "video 1/1 (145/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (146/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (147/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (148/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (149/318) /content/20201009.mp4: 384x640 3 persons, 2 bicycles, Done. (0.030s)\n",
            "video 1/1 (150/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (151/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (152/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (153/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (154/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (155/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (156/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (157/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (158/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (159/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (160/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (161/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (162/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (163/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (164/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (165/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (166/318) /content/20201009.mp4: 384x640 4 persons, Done. (0.030s)\n",
            "video 1/1 (167/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (168/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (169/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (170/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (171/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (172/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (173/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (174/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (175/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (176/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (177/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (178/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (179/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (180/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (181/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (182/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (183/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (184/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (185/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (186/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (187/318) /content/20201009.mp4: 384x640 3 persons, 1 bicycle, Done. (0.030s)\n",
            "video 1/1 (188/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (189/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (190/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (191/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (192/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (193/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (194/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (195/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (196/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (197/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (198/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (199/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (200/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (201/318) /content/20201009.mp4: 384x640 3 persons, 1 elephant, Done. (0.030s)\n",
            "video 1/1 (202/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (203/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (204/318) /content/20201009.mp4: 384x640 3 persons, 1 giraffe, Done. (0.030s)\n",
            "video 1/1 (205/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (206/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (207/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (208/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (209/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (210/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (211/318) /content/20201009.mp4: 384x640 4 persons, Done. (0.030s)\n",
            "video 1/1 (212/318) /content/20201009.mp4: 384x640 4 persons, Done. (0.030s)\n",
            "video 1/1 (213/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (214/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (215/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (216/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (217/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (218/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (219/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (220/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (221/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (222/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (223/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (224/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (225/318) /content/20201009.mp4: 384x640 5 persons, Done. (0.030s)\n",
            "video 1/1 (226/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (227/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (228/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (229/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (230/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (231/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (232/318) /content/20201009.mp4: 384x640 3 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (233/318) /content/20201009.mp4: 384x640 3 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (234/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (235/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (236/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (237/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (238/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (239/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (240/318) /content/20201009.mp4: 384x640 1 person, Done. (0.030s)\n",
            "video 1/1 (241/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (242/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (243/318) /content/20201009.mp4: 384x640 2 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (244/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (245/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (246/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (247/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (248/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (249/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (250/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (251/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (252/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (253/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (254/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (255/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (256/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (257/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (258/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (259/318) /content/20201009.mp4: 384x640 1 person, Done. (0.030s)\n",
            "video 1/1 (260/318) /content/20201009.mp4: 384x640 1 person, Done. (0.030s)\n",
            "video 1/1 (261/318) /content/20201009.mp4: 384x640 2 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (262/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (263/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (264/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (265/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (266/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (267/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (268/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (269/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (270/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (271/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (272/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (273/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (274/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (275/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (276/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (277/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (278/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (279/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (280/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (281/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (282/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (283/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (284/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (285/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (286/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (287/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (288/318) /content/20201009.mp4: 384x640 3 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (289/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (290/318) /content/20201009.mp4: 384x640 4 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (291/318) /content/20201009.mp4: 384x640 3 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (292/318) /content/20201009.mp4: 384x640 4 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (293/318) /content/20201009.mp4: 384x640 4 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (294/318) /content/20201009.mp4: 384x640 4 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (295/318) /content/20201009.mp4: 384x640 4 persons, Done. (0.030s)\n",
            "video 1/1 (296/318) /content/20201009.mp4: 384x640 4 persons, Done. (0.030s)\n",
            "video 1/1 (297/318) /content/20201009.mp4: 384x640 4 persons, Done. (0.030s)\n",
            "video 1/1 (298/318) /content/20201009.mp4: 384x640 4 persons, Done. (0.030s)\n",
            "video 1/1 (299/318) /content/20201009.mp4: 384x640 4 persons, Done. (0.030s)\n",
            "video 1/1 (300/318) /content/20201009.mp4: 384x640 4 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (301/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (302/318) /content/20201009.mp4: 384x640 3 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (303/318) /content/20201009.mp4: 384x640 3 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (304/318) /content/20201009.mp4: 384x640 3 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (305/318) /content/20201009.mp4: 384x640 3 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (306/318) /content/20201009.mp4: 384x640 3 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (307/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (308/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (309/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (310/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (311/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "video 1/1 (312/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (313/318) /content/20201009.mp4: 384x640 3 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (314/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (315/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (316/318) /content/20201009.mp4: 384x640 3 persons, 1 bench, Done. (0.030s)\n",
            "video 1/1 (317/318) /content/20201009.mp4: 384x640 3 persons, Done. (0.030s)\n",
            "video 1/1 (318/318) /content/20201009.mp4: 384x640 2 persons, Done. (0.030s)\n",
            "Speed: 0.5ms pre-process, 30.0ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63h4Pn49DvBm",
        "outputId": "1b1517c8-37e9-4e0f-c0c1-a98f94112cea"
      },
      "source": [
        "!python detect.py --source ../penguins.png"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=../penguins.png, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 🚀 v5.0-499-g48b00db torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
            "image 1/1 /content/penguins.png: 448x640 7 birds, Done. (0.032s)\n",
            "Speed: 0.5ms pre-process, 31.7ms inference, 2.1ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp5\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAGJ_0UYEU_5",
        "outputId": "5bde01e4-14e0-4120-ab00-a7a1c2ea0014"
      },
      "source": [
        "!python detect.py --conf 0.45 --source ../penguins.png\n",
        "#컨피던스 레벨이 좌우"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=../penguins.png, imgsz=[640, 640], conf_thres=0.45, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 🚀 v5.0-499-g48b00db torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
            "image 1/1 /content/penguins.png: 448x640 6 birds, Done. (0.031s)\n",
            "Speed: 0.5ms pre-process, 31.4ms inference, 1.9ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp7\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2b809E8iete",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4317219-5c8a-4d0b-f911-b5d79e697b2a"
      },
      "source": [
        "%cd "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q4aE5EeijdQ"
      },
      "source": [
        "mp4 file from Gogle Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPvtN94MiiIl"
      },
      "source": [
        "!!gdown --id 1OC2podqojyTRLxIvrMpzM2-gMDP5Elss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4Gp2Cuni5Sc"
      },
      "source": [
        "!!gdown --id 1MY3xACdnewNC7XC566V8TUzHAs2df3eg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KnOEqgGjwse"
      },
      "source": [
        "%cd yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywftIMemAaYs"
      },
      "source": [
        "!python detect.py --source ../20201009.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VuZqaxTAnel"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX"
      },
      "source": [
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source ../penguins.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqrv9aEQjb_w"
      },
      "source": [
        "Image(filename='runs/detect/exp2/penguins.png', width=600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qbaa3iEcrcE"
      },
      "source": [
        "Results are saved to `runs/detect`. A full list of available inference sources:\n",
        "<img src=\"https://user-images.githubusercontent.com/26833433/98274798-2b7a7a80-1f94-11eb-91a4-70c73593e26b.jpg\" width=\"900\"> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Test\n",
        "Test a model on [COCO](https://cocodataset.org/#home) val or test-dev dataset to evaluate trained accuracy. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag. Note that `pycocotools` metrics may be 1-2% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyTZYGgRjnMc"
      },
      "source": [
        "## COCO val2017\n",
        "Download [COCO val 2017](https://github.com/ultralytics/yolov5/blob/74b34872fdf41941cddcf243951cdb090fbac17b/data/coco.yaml#L14) dataset (1GB - 5000 images), and test model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQPtK1QYVaD_"
      },
      "source": [
        "# Download COCO val2017\n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017val.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ../ && rm tmp.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH"
      },
      "source": [
        "# Run YOLOv5x on COCO val2017\n",
        "!python detect.py --weights yolov5x.pt --data ./data/coco.yaml --img 640 --iou 0.65"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc_KbFk0juX2"
      },
      "source": [
        "## COCO test-dev2017\n",
        "Download [COCO test2017](https://github.com/ultralytics/yolov5/blob/74b34872fdf41941cddcf243951cdb090fbac17b/data/coco.yaml#L15) dataset (7GB - 40,000 images), to test model accuracy on test-dev set (20,000 images). Results are saved to a `*.json` file which can be submitted to the evaluation server at https://competitions.codalab.org/competitions/20794."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AJnSeCIHyJ"
      },
      "source": [
        "# Download COCO test-dev2017\n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ../ && rm tmp.zip  # unzip labels\n",
        "!f=\"test2017.zip\" && curl http://images.cocodataset.org/zips/$f -o $f && unzip -q $f && rm $f  # 7GB,  41k images\n",
        "%mv ./test2017 ./coco/images && mv ./coco ../  # move images to /coco and move /coco next to /yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29GJXAP_lPrt"
      },
      "source": [
        "# Run YOLOv5s on COCO test-dev2017 using --task test\n",
        "!python test.py --weights yolov5s.pt --data coco.yaml --task test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUOiNLtMP5aG"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "Download [COCO128](https://www.kaggle.com/ultralytics/coco128), a small 128-image tutorial dataset, start tensorboard and train YOLOv5s from a pretrained checkpoint for 3 epochs (note actual training is typically much longer, around **300-1000 epochs**, depending on your dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knxi2ncxWffW"
      },
      "source": [
        "# Download COCO128\n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ../ && rm tmp.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pOkGLv1dMqh"
      },
      "source": [
        "Train a YOLOv5s model on [COCO128](https://www.kaggle.com/ultralytics/coco128) with `--data coco128.yaml`, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and **COCO, COCO128, and VOC datasets are downloaded automatically** on first use.\n",
        "\n",
        "All training results are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOy5KI2ncnWd"
      },
      "source": [
        "# Tensorboard (optional)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fLAV42oNb7M"
      },
      "source": [
        "# Weights & Biases (optional)\n",
        "%pip install -q wandb  \n",
        "!wandb login  # use 'wandb disabled' or 'wandb enabled' to disable or enable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15glLzbQx5u0"
      },
      "source": [
        "# 4. Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLI1JmHU7B0l"
      },
      "source": [
        "## Weights & Biases Logging 🌟 NEW\n",
        "\n",
        "[Weights & Biases](https://www.wandb.com/) (W&B) is now integrated with YOLOv5 for real-time visualization and cloud logging of training runs. This allows for better run comparison and introspection, as well improved visibility and collaboration for teams. To enable W&B `pip install wandb`, and then train normally (you will be guided through setup on first use). \n",
        "\n",
        "During training you will see live updates at [https://wandb.ai/home](https://wandb.ai/home), and you can create and share detailed [Reports](https://wandb.ai/glenn-jocher/yolov5_tutorial/reports/YOLOv5-COCO128-Tutorial-Results--VmlldzozMDI5OTY) of your results. For more information see the [YOLOv5 Weights & Biases Tutorial](https://github.com/ultralytics/yolov5/issues/1289). \n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/26833433/98184457-bd3da580-1f0a-11eb-8461-95d908a71893.jpg\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WPvRbS5Swl6"
      },
      "source": [
        "## Local Logging\n",
        "\n",
        "All results are logged by default to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc. View train and test jpgs to see mosaics, labels, predictions and augmentation effects. Note a **Mosaic Dataloader** is used for training (shown below), a new concept developed by Ultralytics and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riPdhraOTCO0"
      },
      "source": [
        "Image(filename='runs/train/exp/train_batch0.jpg', width=800)  # train batch 0 mosaics and labels\n",
        "Image(filename='runs/train/exp/test_batch0_labels.jpg', width=800)  # test batch 0 labels\n",
        "Image(filename='runs/train/exp/test_batch0_pred.jpg', width=800)  # test batch 0 predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYG4WFEnTVrI"
      },
      "source": [
        "> <img src=\"https://user-images.githubusercontent.com/26833433/83667642-90fcb200-a583-11ea-8fa3-338bbf7da194.jpeg\" width=\"750\">  \n",
        "`train_batch0.jpg` shows train batch 0 mosaics and labels\n",
        "\n",
        "> <img src=\"https://user-images.githubusercontent.com/26833433/83667626-8c37fe00-a583-11ea-997b-0923fe59b29b.jpeg\" width=\"750\">  \n",
        "`test_batch0_labels.jpg` shows test batch 0 labels\n",
        "\n",
        "> <img src=\"https://user-images.githubusercontent.com/26833433/83667635-90641b80-a583-11ea-8075-606316cebb9c.jpeg\" width=\"750\">  \n",
        "`test_batch0_pred.jpg` shows test batch 0 _predictions_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      },
      "source": [
        "Training losses and performance metrics are also logged to [Tensorboard](https://www.tensorflow.org/tensorboard) and a custom `results.txt` logfile which is plotted as `results.png` (below) after training completes. Here we show YOLOv5s trained on COCO128 to 300 epochs, starting from scratch (blue), and from pretrained `--weights yolov5s.pt` (orange)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDznIqPF7nk3"
      },
      "source": [
        "from utils.plots import plot_results \n",
        "plot_results(save_dir='runs/train/exp')  # plot all results*.txt as results.png\n",
        "Image(filename='runs/train/exp/results.png', width=800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfrEegCSW3fK"
      },
      "source": [
        "<img src=\"https://user-images.githubusercontent.com/26833433/97808309-8182b180-1c66-11eb-8461-bffe1a79511d.png\" width=\"800\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zelyeqbyt3GD"
      },
      "source": [
        "# Environments\n",
        "\n",
        "YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):\n",
        "\n",
        "- **Google Colab and Kaggle** notebooks with free GPU: <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a> <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)\n",
        "- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)\n",
        "- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=\"https://hub.docker.com/r/ultralytics/yolov5\"><img src=\"https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker\" alt=\"Docker Pulls\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qu7Iesl0p54"
      },
      "source": [
        "# Status\n",
        "\n",
        "![CI CPU testing](https://github.com/ultralytics/yolov5/workflows/CI%20CPU%20testing/badge.svg)\n",
        "\n",
        "If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 training ([train.py](https://github.com/ultralytics/yolov5/blob/master/train.py)), testing ([test.py](https://github.com/ultralytics/yolov5/blob/master/test.py)), inference ([detect.py](https://github.com/ultralytics/yolov5/blob/master/detect.py)) and export ([export.py](https://github.com/ultralytics/yolov5/blob/master/models/export.py)) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Optional extras below. Unit tests validate repo functionality and should be run on any PRs submitted.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI6NoBev8Ib1"
      },
      "source": [
        "# Re-clone repo\n",
        "%cd ..\n",
        "%rm -rf yolov5 && git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcKoSIK2WSzj"
      },
      "source": [
        "# Reproduce\n",
        "%%shell\n",
        "for x in yolov5s yolov5m yolov5l yolov5x; do\n",
        "  python test.py --weights $x.pt --data coco.yaml --img 640 --conf 0.25 --iou 0.45  # speed\n",
        "  python test.py --weights $x.pt --data coco.yaml --img 640 --conf 0.001 --iou 0.65  # mAP\n",
        "done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGH0ZjkGjejy"
      },
      "source": [
        "# Unit tests\n",
        "%%shell\n",
        "export PYTHONPATH=\"$PWD\"  # to run *.py. files in subdirectories\n",
        "\n",
        "rm -rf runs  # remove runs/\n",
        "for m in yolov5s; do  # models\n",
        "  python train.py --weights $m.pt --epochs 3 --img 320 --device 0  # train pretrained\n",
        "  python train.py --weights '' --cfg $m.yaml --epochs 3 --img 320 --device 0  # train scratch\n",
        "  for d in 0 cpu; do  # devices\n",
        "    python detect.py --weights $m.pt --device $d  # detect official\n",
        "    python detect.py --weights runs/train/exp/weights/best.pt --device $d  # detect custom\n",
        "    python test.py --weights $m.pt --device $d # test official\n",
        "    python test.py --weights runs/train/exp/weights/best.pt --device $d # test custom\n",
        "  done\n",
        "  python hubconf.py  # hub\n",
        "  python models/yolo.py --cfg $m.yaml  # inspect\n",
        "  python models/export.py --weights $m.pt --img 640 --batch 1  # export\n",
        "done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gogI-kwi3Tye"
      },
      "source": [
        "# Profile\n",
        "from utils.torch_utils import profile \n",
        "\n",
        "m1 = lambda x: x * torch.sigmoid(x)\n",
        "m2 = torch.nn.SiLU()\n",
        "profile(x=torch.randn(16, 3, 640, 640), ops=[m1, m2], n=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVRSOhEvUdb5"
      },
      "source": [
        "# Evolve\n",
        "!python train.py --img 640 --batch 64 --epochs 100 --data coco128.yaml --weights yolov5s.pt --cache --noautoanchor --evolve\n",
        "!d=runs/train/evolve && cp evolve.* $d && zip -r evolve.zip $d && gsutil mv evolve.zip gs://bucket  # upload results (optional)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSgFCAcMbk1R"
      },
      "source": [
        "# VOC\n",
        "for b, m in zip([64, 48, 32, 16], ['yolov5s', 'yolov5m', 'yolov5l', 'yolov5x']):  # zip(batch_size, model)\n",
        "  !python train.py --batch {b} --weights {m}.pt --data voc.yaml --epochs 50 --cache --img 512 --nosave --hyp hyp.finetune.yaml --project VOC --name {m}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}